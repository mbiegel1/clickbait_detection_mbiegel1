{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Clickbait Detection Notebook`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Part 1:</b>\n",
    "<br>This first part runs through training four classifiers on training data. Then, the classifiers are tested on either the training data or external data. The accuracy and f1 scores are found for each classifier.\n",
    "\n",
    "<br><u>The four classifiers are:</u>\n",
    "    <br>Multinomial Naive Bayes\n",
    "    <br>Stochastic Gradient Descent\n",
    "    <br>Perceptron\n",
    "    <br>Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\n",
    "# Import cell\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# Used to increase parallel computing on CPU\n",
    "# pip install scikit-learn-intelex\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\n",
    "# Reading data into pandas dataframe\n",
    "\n",
    "# Defining Constants\n",
    "clickbait_title_column = \"headline\"\n",
    "is_clickbait_column = \"clickbait\"\n",
    "\n",
    "# Pandas dataframe df\n",
    "df = pd.read_csv(\"input_data/clickbait_consensus.csv\")\n",
    "\n",
    "y = df[is_clickbait_column]\n",
    "X = df[clickbait_title_column]\n",
    "\n",
    "print(\"Data formated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\n",
    "# Vectorizing data in order for classifiers to use them\n",
    "# This is required because classifiers need to numerical data, \n",
    "#   so the titles (wihch are strings) need to be transformed numerically\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectors = vectorizer.fit_transform(X)\n",
    "\n",
    "print(\"Data vectorized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\n",
    "# Asking user what data to test classifiers on\n",
    "\n",
    "print(\"-------------------------TEST DATA-----------------------------------------\\n\")\n",
    "\n",
    "which_data = input(\"Would you like to test on training data (enter 0) or pre-determined, external data (enter 1)? \")\n",
    "\n",
    "if (which_data == \"0\"):\n",
    "    print(\"Training data chosen\")\n",
    "    test_multi_titles = df[clickbait_title_column]\n",
    "    test_multi_titles_nparray = df[is_clickbait_column].to_numpy()\n",
    "\n",
    "    vectors_test = vectorizer.transform(test_multi_titles)\n",
    "\n",
    "else:\n",
    "    print(\"External data chosen\")\n",
    "    \n",
    "    test_df = pd.read_csv(\"input_data/clickbait_ratio_flattened.csv\")\n",
    "\n",
    "    test_multi_titles = test_df[clickbait_title_column]\n",
    "    test_multi_titles_nparray = test_df[is_clickbait_column].to_numpy()\n",
    "\n",
    "    vectors_test = vectorizer.transform(test_multi_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\n",
    "# Multinomial Naive Bayes Classification\n",
    "\n",
    "print(\"-------------------------MULTINOMIALNB PREDICTING-----------------------------------------\\n\")\n",
    "\n",
    "multiNB_clf = MultinomialNB(alpha=0.00001)\n",
    "multiNB_clf.fit(vectors, y)\n",
    "\n",
    "\n",
    "multiNB_pred = multiNB_clf.predict(vectors_test)\n",
    "\n",
    "print(\"Prediction:\", multiNB_pred)\n",
    "print()\n",
    "\n",
    "acc_score_multiNB = metrics.accuracy_score(test_multi_titles_nparray, multiNB_pred)\n",
    "f1_score_multNB = metrics.f1_score(test_multi_titles_nparray, multiNB_pred, average='macro')\n",
    "\n",
    "print('Total accuracy classification score: {}'.format(acc_score_multiNB))\n",
    "print('Total F1 classification score: {}'.format(f1_score_multNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\n",
    "# Stochastic Gradient Descent Classification\n",
    "\n",
    "print(\"-------------------------STOCHSTIC GRADIENT DESCENT (SGD) PREDICTING---------------------------------------\\n\")\n",
    "\n",
    "SGD_clf = SGDClassifier(loss=\"huber\", penalty=\"l2\", max_iter=1000)\n",
    "SGD_clf.fit(vectors, y)\n",
    "\n",
    "SGD_pred = SGD_clf.predict(vectors_test)\n",
    "\n",
    "print(\"Prediction:\", SGD_pred)\n",
    "print()\n",
    "\n",
    "acc_score_SGD = metrics.accuracy_score(test_multi_titles_nparray, SGD_pred)\n",
    "f1_score_SGD = metrics.f1_score(test_multi_titles_nparray, SGD_pred, average='macro')\n",
    "\n",
    "print('Total accuracy classification score: {}'.format(acc_score_SGD))\n",
    "print('Total F1 classification score: {}'.format(f1_score_SGD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\n",
    "# Perceptron Classification\n",
    "\n",
    "print(\"-------------------------PERCEPTRON PREDICTING---------------------------------------\\n\")\n",
    "\n",
    "perceptron_clf = Perceptron(tol=1e-3, random_state=0)\n",
    "perceptron_clf.fit(vectors, y)\n",
    "\n",
    "perceptron_pred = perceptron_clf.predict(vectors_test)\n",
    "\n",
    "print(\"Prediction:\", perceptron_pred)\n",
    "print()\n",
    "\n",
    "acc_score_perceptron = metrics.accuracy_score(test_multi_titles_nparray, perceptron_pred)\n",
    "f1_score_perceptron = metrics.f1_score(test_multi_titles_nparray, perceptron_pred, average='macro')\n",
    "\n",
    "print('Total accuracy classification score: {}'.format(acc_score_perceptron))\n",
    "print('Total F1 classification score: {}'.format(f1_score_perceptron))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\n",
    "# Support Vector Machine Classification\n",
    "\n",
    "print(\"-------------------------SVM PREDICTING---------------------------------------\\n\")\n",
    "\n",
    "SVM_clf = svm.SVC(gamma=3, kernel='sigmoid')\n",
    "SVM_clf.fit(vectors, y)\n",
    "\n",
    "SVM_pred = SVM_clf.predict(vectors_test)\n",
    "\n",
    "print(\"Prediction:\", SVM_pred)\n",
    "print()\n",
    "\n",
    "acc_score_SVM = metrics.accuracy_score(test_multi_titles_nparray, SVM_pred)\n",
    "f1_score_SVM = metrics.f1_score(test_multi_titles_nparray, SVM_pred, average='macro')\n",
    "\n",
    "print('Total accuracy classification score: {}'.format(acc_score_SVM))\n",
    "print('Total F1 classification score: {}'.format(f1_score_SVM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Part 2</b>\n",
    "<br> Part 2 allows you, the user, to enter in your own titles that you find on the internet or create on your own and run it throught the four classifiers to see if it's clickbait.\n",
    "<br>\n",
    "<br> The notebook will walk through the functions for training the classifiers (same process as above, only it is formatted professionally now). Then, you will be prompted to enter text so that the classifiers can predict clickbait status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Part 2\n",
    "\n",
    "# trainClassifiers() runs a compiled .csv file through all four classifiers of over 30,000 data points.\n",
    "\n",
    "def trainClassifiers():\n",
    "\n",
    "    print(\"\\nTraining classifiers...\", end=\"\")\n",
    "\n",
    "     # Defining Constants\n",
    "    clickbait_title_column = \"headline\"\n",
    "    is_clickbait_column = \"clickbait\"\n",
    "\n",
    "    # Pandas dataframe df\n",
    "    df = pd.read_csv(\"input_data/clickbait_compilation.csv\")\n",
    "\n",
    "\n",
    "    y = df[is_clickbait_column]\n",
    "    X = df[clickbait_title_column].str.lower() # All titles are in lowercase\n",
    "\n",
    "\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectors = vectorizer.fit_transform(X)\n",
    "\n",
    "\n",
    "    # MultinomialNB\n",
    "    multiNB_clf = MultinomialNB(alpha=0.00001)\n",
    "    multiNB_clf.fit(vectors, y)\n",
    "\n",
    "    # SGD\n",
    "    SGD_clf = SGDClassifier(loss=\"huber\", penalty=\"l2\", max_iter=1000)\n",
    "    SGD_clf.fit(vectors, y)\n",
    "\n",
    "    # Perceptron\n",
    "    perceptron_clf = Perceptron(tol=1e-3, random_state=0)\n",
    "    perceptron_clf.fit(vectors, y)\n",
    "\n",
    "    # SVM\n",
    "    SVM_clf = svm.SVC(gamma=3, kernel='sigmoid')\n",
    "    SVM_clf.fit(vectors, y)\n",
    "\n",
    "    print(\"done\")\n",
    "\n",
    "    return vectorizer, multiNB_clf, SGD_clf, perceptron_clf, SVM_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Part 2\n",
    "\n",
    "# predictWithClassifiers() takes the user's entry and predicts clickbait status on all four classifiers\n",
    "\n",
    "def predictWithClassifiers(user_clickbait_title, vectorizer, multiNB_pred, SGD_pred, perceptron_pred, SVM_pred):\n",
    "        \n",
    "        print(\"\\n-----------------------------------------------------------\")\n",
    "        print(\"STATISTICS:\")\n",
    "\n",
    "        # Vectorize the title to pass into the prediction of the classifier\n",
    "        vector_user_title_test = vectorizer.transform(user_clickbait_title)\n",
    "\n",
    "        # Multinomial Prediction\n",
    "        multiNB_pred = multiNB_clf.predict(vector_user_title_test)\n",
    "        print(\"Multinomial Naive Bayes Prediction:\\t\\t\", multiNB_pred)\n",
    "\n",
    "\n",
    "        # Stochastic Gradient Descent Prediction\n",
    "        SGD_pred = SGD_clf.predict(vector_user_title_test)\n",
    "        print(\"Stochastic Gradient Descent Prediction:\\t\\t\", SGD_pred)\n",
    "\n",
    "\n",
    "        # Perceptron Prediction\n",
    "        perceptron_pred = perceptron_clf.predict(vector_user_title_test)\n",
    "        print(\"Perceptron Prediction:\\t\\t\\t\\t\", perceptron_pred)\n",
    "        \n",
    "\n",
    "        # SVM prediction\n",
    "        SVM_pred = SVM_clf.predict(vector_user_title_test)\n",
    "        print(\"Support Vector Machine Prediction:\\t\\t\", SVM_pred)\n",
    "\n",
    "        return multiNB_pred, SGD_pred, perceptron_pred, SVM_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Part 2\n",
    "\n",
    "# classifierClickbaitStatus()) finds the clickbait status of all four classifiers by averaging their predictions\n",
    "# Prediction values are [0] for a non-clickbait title and [1] for a clickbait title\n",
    "\n",
    "def classifierClickbaitRatio(multiNB_pred, SGD_pred, perceptron_pred, SVM_pred):\n",
    "    classifier_clickbait_ratio = (multiNB_pred+SGD_pred+perceptron_pred+SVM_pred)/ num_of_classifiers\n",
    "\n",
    "    print(\"\\nTotal Classification Clickbait Status:\\t\\t\\t\", classifier_clickbait_ratio)\n",
    "    print(\"\\n-----------------------------------------------------------\")\n",
    "\n",
    "    return classifier_clickbait_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Part 2\n",
    "\n",
    "# determineClickbait() determines if the title is clickbait based on the four classifier predictions\n",
    "\n",
    "def determineClickbait(classifier_clickbait_ratio, prediction_threshold):\n",
    "    # If the classifier accuracy is above the threshold, title is clickbait\n",
    "    # Else, it's below the threshold, so title is not clickbait\n",
    "    \n",
    "    if (classifier_clickbait_ratio >= prediction_threshold):\n",
    "        print(\"\\nCLICKBAIT!\")\n",
    "    else:\n",
    "        print(\"\\nNOT CLICKBAIT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Part 2\n",
    "\n",
    "# This cell trains the classifiers on the training data\n",
    "\n",
    "# Constants\n",
    "num_of_classifiers = 4\n",
    "prediction_threshold = 0.75\n",
    "\n",
    "# train Classifiers on over 30,000 data points\n",
    "vectorizer, multiNB_clf, SGD_clf, perceptron_clf, SVM_clf = trainClassifiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Part 2\n",
    "\n",
    "# This cell asks for user input and runs prediction on the input\n",
    "# Displays results of prediction as well as clickbait determination\n",
    "\n",
    "# Get user clickbait title\n",
    "user_clickbait_title = input(\"\\n\\nEnter a title to see if it's clickbait (-1 to quit):\\n\").lower()\n",
    "\n",
    "if (user_clickbait_title != \"-1\"):\n",
    "\n",
    "    # Turn string title into list iterable for vectorization\n",
    "    user_clickbait_title = [user_clickbait_title]\n",
    "\n",
    "    # Predicting the clickbait classification on all classifiers\n",
    "    multiNB_pred, SGD_pred, perceptron_pred, SVM_pred = predictWithClassifiers(user_clickbait_title, vectorizer, multiNB_clf, SGD_clf, perceptron_clf, SVM_clf)\n",
    "\n",
    "    # Total mean classifier accuracy to determine if the title is clickbait\n",
    "    classifier_clickbait_ratio = classifierClickbaitRatio(multiNB_pred, SGD_pred, perceptron_pred, SVM_pred)\n",
    "\n",
    "    # Determing that clickbait status of the user's title\n",
    "    determineClickbait(classifier_clickbait_ratio, prediction_threshold)\n",
    "\n",
    "else:\n",
    "    print(\"Bye now!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "478_kernel",
   "language": "python",
   "name": "478_kernel"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
