{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Clickbait Detection Notebook`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: asttokens==2.0.5 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (2.0.5)\n",
      "Requirement already satisfied: backcall==0.2.0 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (0.2.0)\n",
      "Collecting cycler==0.11.0\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting daal==2021.5.3\n",
      "  Using cached daal-2021.5.3-py2.py3-none-manylinux1_x86_64.whl (284.3 MB)\n",
      "Collecting daal4py==2021.5.3\n",
      "  Using cached daal4py-2021.5.3-py38-none-manylinux1_x86_64.whl (22.6 MB)\n",
      "Requirement already satisfied: debugpy==1.6.0 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (1.6.0)\n",
      "Requirement already satisfied: decorator==5.1.1 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (5.1.1)\n",
      "Requirement already satisfied: entrypoints==0.4 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (0.4)\n",
      "Requirement already satisfied: executing==0.8.3 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (0.8.3)\n",
      "Collecting fonttools==4.33.3\n",
      "  Using cached fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
      "Requirement already satisfied: ipykernel==6.13.0 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 11)) (6.13.0)\n",
      "Requirement already satisfied: ipython==8.3.0 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 12)) (8.3.0)\n",
      "Requirement already satisfied: jedi==0.18.1 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 13)) (0.18.1)\n",
      "Collecting joblib==1.1.0\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Requirement already satisfied: jupyter-client==7.3.1 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 15)) (7.3.1)\n",
      "Requirement already satisfied: jupyter-core==4.10.0 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 16)) (4.10.0)\n",
      "Collecting kiwisolver==1.4.2\n",
      "  Using cached kiwisolver-1.4.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "Collecting matplotlib==3.5.2\n",
      "  Using cached matplotlib-3.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.3 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 19)) (0.1.3)\n",
      "Requirement already satisfied: nest-asyncio==1.5.5 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 20)) (1.5.5)\n",
      "Collecting numpy==1.22.4\n",
      "  Using cached numpy-1.22.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.9 MB)\n",
      "Requirement already satisfied: packaging==21.3 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 22)) (21.3)\n",
      "Collecting pandas==1.4.2\n",
      "  Using cached pandas-1.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "Requirement already satisfied: parso==0.8.3 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 24)) (0.8.3)\n",
      "Requirement already satisfied: pexpect==4.8.0 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 25)) (4.8.0)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 26)) (0.7.5)\n",
      "Collecting Pillow==9.1.1\n",
      "  Using cached Pillow-9.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Requirement already satisfied: prompt-toolkit==3.0.29 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 28)) (3.0.29)\n",
      "Requirement already satisfied: psutil==5.9.1 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 29)) (5.9.1)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 30)) (0.7.0)\n",
      "Requirement already satisfied: pure-eval==0.2.2 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 31)) (0.2.2)\n",
      "Requirement already satisfied: Pygments==2.12.0 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 32)) (2.12.0)\n",
      "Requirement already satisfied: pyparsing==3.0.9 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 33)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 34)) (2.8.2)\n",
      "Collecting pytz==2022.1\n",
      "  Using cached pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
      "Requirement already satisfied: pyzmq==23.0.0 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 36)) (23.0.0)\n",
      "Collecting scikit-learn==1.1.1\n",
      "  Using cached scikit_learn-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
      "Collecting scikit-learn-intelex==2021.5.3\n",
      "  Using cached scikit_learn_intelex-2021.5.3-py38-none-manylinux1_x86_64.whl (69 kB)\n",
      "Collecting scipy==1.8.1\n",
      "  Using cached scipy-1.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.6 MB)\n",
      "Requirement already satisfied: six==1.16.0 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 40)) (1.16.0)\n",
      "Processing /home/mtbiegel/.cache/pip/wheels/22/0b/40/fd3f795caaa1fb4c6cb738bc1f56100be1e57da95849bfc897/sklearn-0.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: stack-data==0.2.0 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 42)) (0.2.0)\n",
      "Collecting tbb==2021.6.0\n",
      "  Using cached tbb-2021.6.0-py2.py3-none-manylinux1_x86_64.whl (4.0 MB)\n",
      "Collecting threadpoolctl==3.1.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: tornado==6.1 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 45)) (6.1)\n",
      "Requirement already satisfied: traitlets==5.2.1.post0 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 46)) (5.2.1.post0)\n",
      "Requirement already satisfied: wcwidth==0.2.5 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from -r requirements.txt (line 47)) (0.2.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/mtbiegel/cmsc_478/test_env/lib/python3.8/site-packages (from ipython==8.3.0->-r requirements.txt (line 12)) (44.0.0)\n",
      "Installing collected packages: cycler, tbb, daal, numpy, daal4py, fonttools, joblib, kiwisolver, Pillow, matplotlib, pytz, pandas, scipy, threadpoolctl, scikit-learn, scikit-learn-intelex, sklearn\n",
      "Successfully installed Pillow-9.1.1 cycler-0.11.0 daal-2021.5.3 daal4py-2021.5.3 fonttools-4.33.3 joblib-1.1.0 kiwisolver-1.4.2 matplotlib-3.5.2 numpy-1.22.4 pandas-1.4.2 pytz-2022.1 scikit-learn-1.1.1 scikit-learn-intelex-2021.5.3 scipy-1.8.1 sklearn-0.0 tbb-2021.6.0 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Part 1:</b>\n",
    "<br>This first part runs through training four classifiers on training data. Then, the classifiers are tested on either the training data or external data. The accuracy and f1 scores are found for each classifier.\n",
    "\n",
    "<br><u>The four classifiers are:</u>\n",
    "    <br>Multinomial Naive Bayes\n",
    "    <br>Stochastic Gradient Descent\n",
    "    <br>Perceptron\n",
    "    <br>Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\n",
    "# Import cell\n",
    "# MAY HAVE TO RUN CELL TWICE IF IT PRODUCES ERRORS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Used to increase parallel computing on CPU\n",
    "# pip install scikit-learn-intelex\n",
    "# Uncomment `from sklearnex import patch_sklearn` to import the patch\n",
    "#from sklearnex import patch_sklearn\n",
    "\n",
    "# Uncomment `patch_sklearn()` function in to enable the patch\n",
    "# Doesn't work all the time, so that's why it's commented out\n",
    "#patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\n",
    "# Reading data into pandas dataframe\n",
    "\n",
    "# Defining Constants\n",
    "clickbait_title_column = \"headline\"\n",
    "is_clickbait_column = \"clickbait\"\n",
    "\n",
    "# Pandas dataframe df\n",
    "df = pd.read_csv(\"input_data/clickbait_consensus.csv\")\n",
    "\n",
    "y = df[is_clickbait_column]\n",
    "X = df[clickbait_title_column]\n",
    "\n",
    "print(\"Data formated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\n",
    "# Vectorizing data in order for classifiers to use them\n",
    "# This is required because classifiers need to numerical data, \n",
    "#   so the titles (wihch are strings) need to be transformed numerically\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectors = vectorizer.fit_transform(X)\n",
    "\n",
    "print(\"Data vectorized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\n",
    "# Asking user what data to test classifiers on\n",
    "\n",
    "print(\"-------------------------TEST DATA-----------------------------------------\\n\")\n",
    "\n",
    "which_data = input(\"Would you like to test on training data (enter 0) or pre-determined, external data (enter 1)? \")\n",
    "\n",
    "if (which_data == \"0\"):\n",
    "    print(\"Training data chosen\")\n",
    "    test_multi_titles = df[clickbait_title_column]\n",
    "    test_multi_titles_nparray = df[is_clickbait_column].to_numpy()\n",
    "\n",
    "    vectors_test = vectorizer.transform(test_multi_titles)\n",
    "\n",
    "else:\n",
    "    print(\"External data chosen\")\n",
    "    \n",
    "    test_df = pd.read_csv(\"input_data/clickbait_ratio_flattened.csv\")\n",
    "\n",
    "    test_multi_titles = test_df[clickbait_title_column]\n",
    "    test_multi_titles_nparray = test_df[is_clickbait_column].to_numpy()\n",
    "\n",
    "    vectors_test = vectorizer.transform(test_multi_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\n",
    "# Multinomial Naive Bayes Classification\n",
    "\n",
    "print(\"-------------------------MULTINOMIALNB PREDICTING-----------------------------------------\\n\")\n",
    "\n",
    "multiNB_clf = MultinomialNB(alpha=0.00001)\n",
    "multiNB_clf.fit(vectors, y)\n",
    "\n",
    "\n",
    "multiNB_pred = multiNB_clf.predict(vectors_test)\n",
    "\n",
    "print(\"Prediction:\", multiNB_pred)\n",
    "print()\n",
    "\n",
    "acc_score_multiNB = metrics.accuracy_score(test_multi_titles_nparray, multiNB_pred)\n",
    "f1_score_multNB = metrics.f1_score(test_multi_titles_nparray, multiNB_pred, average='macro')\n",
    "roc_score_multiNB = metrics.roc_auc_score(test_multi_titles_nparray, multiNB_pred)\n",
    "\n",
    "print('Total accuracy classification score: {}'.format(acc_score_multiNB))\n",
    "print('Total F1 classification score: {}'.format(f1_score_multNB))\n",
    "print('Total ROC classification score: {}'.format(roc_score_multiNB))\n",
    "\n",
    "# precision_score_multiNB = metrics.precision_score(test_multi_titles_nparray, multiNB_pred, average='macro')\n",
    "# recall_score_multiNB = metrics.recall_score(test_multi_titles_nparray, multiNB_pred, average='macro')\n",
    "\n",
    "# print('\\nTotal precision score: {}'.format(precision_score_multiNB))\n",
    "# print('Total recall score: {}'.format(recall_score_multiNB))\n",
    "\n",
    "# Get data for ROC Curve\n",
    "multiNB_fpr, multiNB_tpr, thresholds = metrics.roc_curve(test_multi_titles_nparray, multiNB_pred)\n",
    "\n",
    "# Create ROC curve\n",
    "plt.plot(multiNB_fpr, multiNB_tpr)\n",
    "\n",
    "# Add axis labels to plot\n",
    "plt.title('Multinomial Naive Bayes ROC Curve')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "\n",
    "# Display plot and save plot as jpg\n",
    "#plt.show()\n",
    "plt.savefig(\"mulitNB_roc_curve.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\n",
    "# Stochastic Gradient Descent Classification\n",
    "\n",
    "print(\"-------------------------STOCHSTIC GRADIENT DESCENT (SGD) PREDICTING---------------------------------------\\n\")\n",
    "\n",
    "SGD_clf = SGDClassifier(loss=\"huber\", penalty=\"l2\", max_iter=5000)\n",
    "SGD_clf.fit(vectors, y)\n",
    "\n",
    "SGD_pred = SGD_clf.predict(vectors_test)\n",
    "\n",
    "print(\"Prediction:\", SGD_pred)\n",
    "print()\n",
    "\n",
    "acc_score_SGD = metrics.accuracy_score(test_multi_titles_nparray, SGD_pred)\n",
    "f1_score_SGD = metrics.f1_score(test_multi_titles_nparray, SGD_pred, average='macro')\n",
    "roc_score_SGD = metrics.roc_auc_score(test_multi_titles_nparray, SGD_pred)\n",
    "\n",
    "print('Total accuracy classification score: {}'.format(acc_score_SGD))\n",
    "print('Total F1 classification score: {}'.format(f1_score_SGD))\n",
    "print('Total ROC classification score: {}'.format(roc_score_SGD))\n",
    "\n",
    "\n",
    "# Get data for ROC Curve\n",
    "SGD_fpr, SGD_tpr, thresholds = metrics.roc_curve(test_multi_titles_nparray, multiNB_pred)\n",
    "\n",
    "# Create ROC curve\n",
    "plt.plot(SGD_fpr, SGD_tpr)\n",
    "\n",
    "# Add axis labels to plot\n",
    "plt.title('Stochastic Gradient Descent ROC Curve')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "\n",
    "# Display plot and save plot as jpg\n",
    "#plt.show()\n",
    "plt.savefig(\"SGD_roc_curve.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\n",
    "# Perceptron Classification\n",
    "\n",
    "print(\"-------------------------PERCEPTRON PREDICTING---------------------------------------\\n\")\n",
    "\n",
    "perceptron_clf = Perceptron(tol=1e-3, random_state=0)\n",
    "perceptron_clf.fit(vectors, y)\n",
    "\n",
    "perceptron_pred = perceptron_clf.predict(vectors_test)\n",
    "\n",
    "print(\"Prediction:\", perceptron_pred)\n",
    "print()\n",
    "\n",
    "acc_score_perceptron = metrics.accuracy_score(test_multi_titles_nparray, perceptron_pred)\n",
    "f1_score_perceptron = metrics.f1_score(test_multi_titles_nparray, perceptron_pred, average='macro')\n",
    "roc_score_perceptron = metrics.roc_auc_score(test_multi_titles_nparray, perceptron_pred)\n",
    "\n",
    "print('Total accuracy classification score: {}'.format(acc_score_perceptron))\n",
    "print('Total F1 classification score: {}'.format(f1_score_perceptron))\n",
    "print('Total ROC classification score: {}'.format(roc_score_perceptron))\n",
    "\n",
    "\n",
    "# Get data for ROC Curve\n",
    "perceptron_fpr, perceptron_tpr, thresholds = metrics.roc_curve(test_multi_titles_nparray, multiNB_pred)\n",
    "\n",
    "# Create ROC curve\n",
    "plt.plot(perceptron_fpr, perceptron_tpr)\n",
    "\n",
    "# Add axis labels to plot\n",
    "plt.title('Perceptron ROC Curve')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "\n",
    "# Display plot and save plot as jpg\n",
    "#plt.show()\n",
    "plt.savefig(\"perceptron_roc_curve.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\n",
    "# Support Vector Machine Classification\n",
    "\n",
    "print(\"-------------------------SVM PREDICTING---------------------------------------\\n\")\n",
    "\n",
    "SVM_clf = svm.SVC(gamma=3, kernel='sigmoid')\n",
    "SVM_clf.fit(vectors, y)\n",
    "\n",
    "SVM_pred = SVM_clf.predict(vectors_test)\n",
    "\n",
    "print(\"Prediction:\", SVM_pred)\n",
    "print()\n",
    "\n",
    "acc_score_SVM = metrics.accuracy_score(test_multi_titles_nparray, SVM_pred)\n",
    "f1_score_SVM = metrics.f1_score(test_multi_titles_nparray, SVM_pred, average='macro')\n",
    "roc_score_SVM = metrics.roc_auc_score(test_multi_titles_nparray, SVM_pred)\n",
    "\n",
    "print('Total accuracy classification score: {}'.format(acc_score_SVM))\n",
    "print('Total F1 classification score: {}'.format(f1_score_SVM))\n",
    "print('Total ROC classification score: {}'.format(roc_score_SVM))\n",
    "\n",
    "\n",
    "# Get data for ROC Curve\n",
    "SVM_fpr, SVM_tpr, thresholds = metrics.roc_curve(test_multi_titles_nparray, multiNB_pred)\n",
    "\n",
    "# Create ROC curve\n",
    "plt.plot(SVM_fpr, SVM_tpr)\n",
    "\n",
    "# Add axis labels to plot\n",
    "plt.title('Support Vector Machine ROC Curve')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "\n",
    "# Display plot and save plot as jpg\n",
    "#plt.show()\n",
    "plt.savefig(\"SVM_roc_curve.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Part 2</b>\n",
    "<br> Part 2 allows you, the user, to enter in your own titles that you find on the internet or create on your own and run it throught the four classifiers to see if it's clickbait.\n",
    "<br>\n",
    "<br> The notebook will walk through the functions for training the classifiers (same process as above, only it is formatted professionally now). Then, you will be prompted to enter text so that the classifiers can predict clickbait status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2\n",
    "\n",
    "# trainClassifiers() runs a compiled .csv file through all four classifiers of over 30,000 data points.\n",
    "\n",
    "def trainClassifiers():\n",
    "\n",
    "    print(\"\\nTraining classifiers...\", end=\"\")\n",
    "\n",
    "     # Defining Constants\n",
    "    clickbait_title_column = \"headline\"\n",
    "    is_clickbait_column = \"clickbait\"\n",
    "\n",
    "    # Pandas dataframe df\n",
    "    df = pd.read_csv(\"input_data/clickbait_compilation.csv\")\n",
    "\n",
    "\n",
    "    y = df[is_clickbait_column]\n",
    "    X = df[clickbait_title_column].str.lower() # All titles are in lowercase\n",
    "\n",
    "\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectors = vectorizer.fit_transform(X)\n",
    "\n",
    "\n",
    "    # MultinomialNB\n",
    "    multiNB_clf = MultinomialNB(alpha=0.00001)\n",
    "    multiNB_clf.fit(vectors, y)\n",
    "\n",
    "    # SGD\n",
    "    SGD_clf = SGDClassifier(loss=\"huber\", penalty=\"l2\", max_iter=5000)\n",
    "    SGD_clf.fit(vectors, y)\n",
    "\n",
    "    # Perceptron\n",
    "    perceptron_clf = Perceptron(tol=1e-3, random_state=0)\n",
    "    perceptron_clf.fit(vectors, y)\n",
    "\n",
    "    # SVM\n",
    "    SVM_clf = svm.SVC(gamma=3, kernel='sigmoid')\n",
    "    SVM_clf.fit(vectors, y)\n",
    "\n",
    "    print(\"done\")\n",
    "\n",
    "    return vectorizer, multiNB_clf, SGD_clf, perceptron_clf, SVM_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2\n",
    "\n",
    "# predictWithClassifiers() takes the user's entry and predicts clickbait status on all four classifiers\n",
    "\n",
    "def predictWithClassifiers(user_clickbait_title, vectorizer, multiNB_pred, SGD_pred, perceptron_pred, SVM_pred):\n",
    "        \n",
    "        print(\"\\n-----------------------------------------------------------\")\n",
    "        print(\"STATISTICS:\")\n",
    "\n",
    "        # Vectorize the title to pass into the prediction of the classifier\n",
    "        vector_user_title_test = vectorizer.transform(user_clickbait_title)\n",
    "\n",
    "        # Multinomial Prediction\n",
    "        multiNB_pred = multiNB_clf.predict(vector_user_title_test)\n",
    "        print(\"Multinomial Naive Bayes Prediction:\\t\\t\", multiNB_pred)\n",
    "\n",
    "\n",
    "        # Stochastic Gradient Descent Prediction\n",
    "        SGD_pred = SGD_clf.predict(vector_user_title_test)\n",
    "        print(\"Stochastic Gradient Descent Prediction:\\t\\t\", SGD_pred)\n",
    "\n",
    "\n",
    "        # Perceptron Prediction\n",
    "        perceptron_pred = perceptron_clf.predict(vector_user_title_test)\n",
    "        print(\"Perceptron Prediction:\\t\\t\\t\\t\", perceptron_pred)\n",
    "        \n",
    "\n",
    "        # SVM prediction\n",
    "        SVM_pred = SVM_clf.predict(vector_user_title_test)\n",
    "        print(\"Support Vector Machine Prediction:\\t\\t\", SVM_pred)\n",
    "\n",
    "        return multiNB_pred, SGD_pred, perceptron_pred, SVM_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2\n",
    "\n",
    "# classifierClickbaitStatus()) finds the clickbait status of all four classifiers by averaging their predictions\n",
    "# Prediction values are [0] for a non-clickbait title and [1] for a clickbait title\n",
    "\n",
    "def classifierClickbaitRatio(multiNB_pred, SGD_pred, perceptron_pred, SVM_pred):\n",
    "    classifier_clickbait_ratio = (multiNB_pred+SGD_pred+perceptron_pred+SVM_pred)/ num_of_classifiers\n",
    "\n",
    "    print(\"\\nTotal Classification Clickbait Status:\\t\\t\\t\", classifier_clickbait_ratio)\n",
    "    print(\"\\n-----------------------------------------------------------\")\n",
    "\n",
    "    return classifier_clickbait_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2\n",
    "\n",
    "# determineClickbait() determines if the title is clickbait based on the four classifier predictions\n",
    "\n",
    "def determineClickbait(classifier_clickbait_ratio, isClickbait_threshold, possiblyClickbait_threshold):\n",
    "    # If the classifier accuracy is above the threshold, title is clickbait\n",
    "    # Else, it's below the threshold, so title is not clickbait\n",
    "    \n",
    "    if (classifier_clickbait_ratio >= isClickbait_threshold):\n",
    "        print(\"\\nCLICKBAIT\")\n",
    "    elif (classifier_clickbait_ratio == possiblyClickbait_threshold):\n",
    "        print(\"\\nPOSSIBLY CLICKBAIT\")\n",
    "    else:\n",
    "        print(\"\\nNOT CLICKBAIT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2\n",
    "\n",
    "# This cell trains the classifiers on the training data\n",
    "\n",
    "# train Classifiers on over 30,000 data points\n",
    "vectorizer, multiNB_clf, SGD_clf, perceptron_clf, SVM_clf = trainClassifiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2\n",
    "\n",
    "# This cell asks for user input and runs prediction on the input\n",
    "# Displays results of prediction as well as clickbait determination\n",
    "\n",
    "# Constants\n",
    "num_of_classifiers = 4\n",
    "isClickbait_threshold = 0.75\n",
    "possiblyClickbait_threshold = 0.5\n",
    "\n",
    "# Get user clickbait title\n",
    "user_clickbait_title = input(\"\\n\\nEnter a title to see if it's clickbait (-1 to quit):\\n\").lower()\n",
    "\n",
    "if (user_clickbait_title != \"-1\"):\n",
    "\n",
    "    # Turn string title into list iterable for vectorization\n",
    "    user_clickbait_title = [user_clickbait_title]\n",
    "\n",
    "    # Predicting the clickbait classification on all classifiers\n",
    "    multiNB_pred, SGD_pred, perceptron_pred, SVM_pred = predictWithClassifiers(user_clickbait_title, vectorizer, multiNB_clf, SGD_clf, perceptron_clf, SVM_clf)\n",
    "\n",
    "    # Total mean classifier accuracy to determine if the title is clickbait\n",
    "    classifier_clickbait_ratio = classifierClickbaitRatio(multiNB_pred, SGD_pred, perceptron_pred, SVM_pred)\n",
    "\n",
    "    # Determing that clickbait status of the user's title\n",
    "    determineClickbait(classifier_clickbait_ratio, isClickbait_threshold, possiblyClickbait_threshold)\n",
    "\n",
    "else:\n",
    "    print(\"Bye now!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
